#include "MainEntryHelper.h"

// Note: Concurrency and parallelism

// Time slicing: Concurrent threads executed on machines with only one CPU core.
// Although time slicing will cause context-switch and cache miss more frequently.

// Remember that thread is scheduled by OS, it is not bound to any core.
// We should always strive to minimize the number of shared resources between threads.

// Multiple threads accessing same sharing data cause 'thread contention'.
// Adding more CPU cores will not improve performance if the degree of contention is high.

// Concurrency support was first introduced in C++11 and has since been extended into C++14, C++17, and C++20.
// Before concurrency was part of the language, it was implemented with native concurrency support from the operating system,
// POSIX Threads (pthreads), or some other library.
// For example, there is no support in the C++ standard library for setting thread priorities,
// configuring CPU affinity( CPU pinning ), or setting the stack size of new threads.

// Performance Guideline:
// 1. Avoid contention. Minimize the critical section.
//    Use mutex and atomic will disable optimization in the code generated by the compiler. 
// 2. Avoid blocking operations.
// 3. Number of threads/CPU cores.
//    Increase the number of threads in a task will _NOT_ increase the performance,
//    instead more thread make contention happens more often.
// 4. Thread priorities.
//    The priority of a thread affects how the thread is scheduled.
//    A thread with high priority is likely to be scheduled more often than threads with lower priorities.
//    Thread priorities are important for lowering the latency of tasks.
//    One phenomenon related to thread priorities that can hurt the performance, and should be avoided, is called priority inversion.
//    It happens when a thread with high priority is waiting to acquire a lock that is currently held by a low-priority thread.
//    Such dependencies hurt the high-priority thread, which is blocked until
//    the next time the low-priority thread gets scheduled so that it can release the lock.
// 5. Thread affinity. In other words, this is a request to the scheduler that some threads
//    should be executed on a particular core if possible, to minimize cache misses.
// 6. False sharing (or destructive interference).
//    std::hardware_destructive_interference_size (C++17) to query the cache line size. 

// Manually Header
void Thread();
void CriticalSection();
void ProducerAndConsumer();
void FutureAndPromise();
void AdditionalInCpp20();
void MemoryModel();
void CompilerOptimization();

int main()
{
	Entry( Thread );
	Entry( CriticalSection );
	Entry( ProducerAndConsumer );
	Entry( FutureAndPromise );
	Entry( AdditionalInCpp20 );
	Entry( MemoryModel );
	Entry( CompilerOptimization );
}